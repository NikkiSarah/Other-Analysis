{"cells":[{"source":"Use Keras models with seq2seq neural networks to build a better translation tool.","metadata":{"id":"bA5ajAmk7XH6","tags":[]},"cell_type":"markdown","id":"e8ce123a-8d26-43a4-959e-8c91beeb6ec9"},{"source":"**Pre-processing**","metadata":{},"cell_type":"markdown","id":"cbd29357-76df-40fd-905e-3dca6e9448b4"},{"source":"import numpy as np\nimport re","metadata":{},"cell_type":"code","id":"4d0d6385-1959-4fdc-bd47-928b984025f9","execution_count":3,"outputs":[]},{"source":"# Importing our translations\n# for example: \"spa.txt\" or \"spa-eng/spa.txt\"\ndata_path = \"deu-eng/deu.txt\"\n\n# Defining lines as a list of each line\nwith open(data_path, 'r', encoding='utf-8') as f:\n    lines = f.read().split('\\n')","metadata":{},"cell_type":"code","id":"235d5351-f7b5-404f-b72f-0b69d1874e7c","execution_count":4,"outputs":[]},{"source":"# Create empty lists to hold sentences\ninput_docs = []\ntarget_docs = []\n# Create empty vocabulary sets\ninput_tokens = set()\ntarget_tokens = set()\n\n# Adjust the number of lines so that preprocessing doesn't take too long\nfor line in lines[:7500]:\n    # Input and target sentences are separated by tabs\n    input_doc, target_doc = line.split('\\t')[:2]\n    # Append each input sentence to input_docs\n    input_docs.append(input_doc)\n    # Separate words from punctuation\n    target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n    # Redefine target_doc below and append it to target_docs:\n    target_doc = '<START> ' + target_doc + ' <END>'\n    target_docs.append(target_doc)\n\n    # Split up each sentence into words and add each unique word to our vocabulary set\n    for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n    # print(token)\n        if token not in input_tokens:\n            input_tokens.add(token)\n    for token in target_doc.split():\n    # print(token)\n        if token not in target_tokens:\n            target_tokens.add(token)\n\ninput_tokens = sorted(list(input_tokens))\ntarget_tokens = sorted(list(target_tokens))\n\n# Create num_encoder_tokens and num_decoder_tokens:\n# Length of the input tokens set\nnum_encoder_tokens = len(input_tokens)\n# Length of the target tokens set\nnum_decoder_tokens = len(target_tokens)\n\nmax_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\nmax_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n\nprint('Number of samples:', len(input_docs))\nprint('Number of unique input tokens:', num_encoder_tokens)\nprint('Number of unique output tokens:', num_decoder_tokens)\nprint('Max sequence length for inputs:', max_encoder_seq_length)\nprint('Max sequence length for outputs:', max_decoder_seq_length)\n\n# Define dictionary for input vocabulary\ninput_features_dict = dict([(token, i) for i, token in enumerate(input_tokens)])\n# Repeat for target vocabulary\ntarget_features_dict = dict([(token, i) for i, token in enumerate(target_tokens)])\n\n# Reverse lookup token index to decode sequences back to something readable\n# i.e. just swaps the keys and values\nreverse_input_features_dict = dict((i, token) for token, i in input_features_dict.items())\n# Repeat for target\nreverse_target_features_dict = dict((i, token) for token, i in target_features_dict.items())\n\n# Create an empty matrix for the data we'll pass into the encoder\nencoder_input_data = np.zeros((len(input_docs), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\nprint(\"\\nHere's the first item in the encoder input matrix:\\n\", encoder_input_data[0], \n      \"\\n\\nThe number of columns should match the number of unique input tokens and the number of rows should match the maximum sequence length for input sentences.\")\n# Create an empty matrix for the data we'll pass into the decoder\ndecoder_input_data = np.zeros((len(input_docs), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n# Create an empty matrix for the data we expect the decoder to produce\ndecoder_target_data = np.zeros((len(input_docs), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n\nfor line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n        # print(\"Encoder input timestep & token: \", timestep, token)\n        # print(input_features_dict[token])\n        # Assign 1. for the current line, timestep, & word in encoder_input_data:\n        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n\n    for timestep, token in enumerate(target_doc.split()):\n        # decoder_target_data is ahead of decoder_input_data by one timestep\n        # print(\"Decoder input timestep & token:\", timestep, token)\n        # # Assign 1. for the current line, timestep, & word in decoder_input_data:\n        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n        if timestep > 0:\n            # # decoder target is ahead by 1 timestep and doesn't include the start token\n            # print(\"Decoder target timestep:\", timestep)\n            # Assign 1. for the current line, timestep, & word in decoder_target_data:\n            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.","metadata":{},"cell_type":"code","id":"403a233b-f6cc-4033-b0b6-b9be4fbc3677","execution_count":5,"outputs":[{"name":"stdout","text":"Number of samples: 7500\nNumber of unique input tokens: 1997\nNumber of unique output tokens: 3296\nMax sequence length for inputs: 8\nMax sequence length for outputs: 15\n\nHere's the first item in the encoder input matrix:\n [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]] \n\nThe number of columns should match the number of unique input tokens and the number of rows should match the maximum sequence length for input sentences.\n","output_type":"stream"}]},{"source":"print(list(input_features_dict.keys())[:50])\nprint(reverse_target_features_dict[50])\nprint(len(input_tokens))","metadata":{},"cell_type":"code","id":"1edc8824-da2b-4826-a4b9-c094baa1e247","execution_count":6,"outputs":[{"name":"stdout","text":"['!', '\"', '$', '%', ',', '.', '00', '10', '15', '17', '18', '19', '2', '3', '30', '300', '45', '5', '50', '7', '8', '9', '99', ':', '?', 'A', 'Abandon', 'Add', 'Aim', 'Air', 'All', 'Am', 'Answer', 'Any', 'Anybody', 'Anyone', 'Anything', 'Arabs', 'Are', 'Asian', 'Ask', 'Attack', 'Austrian', 'Awesome', 'Back', 'Baking', 'Be', 'Beat', 'Beef', \"Beer's\"]\nAntwortet\n1997\n","output_type":"stream"}]},{"source":"**Training Model**","metadata":{},"cell_type":"markdown","id":"45dd2600-9602-4408-91c8-2bd6397df123"},{"source":"# from preprocessing import num_encoder_tokens, num_decoder_tokens, decoder_target_data, encoder_input_data, decoder_input_data, decoder_target_data\nfrom tensorflow import keras\nfrom keras.layers import Input, LSTM, Dense\nfrom keras.models import Model\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{},"cell_type":"code","id":"25c3f2b7-b0f5-4deb-98a7-e895c9d2a251","execution_count":7,"outputs":[{"name":"stderr","text":"2023-04-13 12:01:38.127147: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2023-04-13 12:01:38.127173: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","output_type":"stream"}]},{"source":"# Choose a latent dimensionality. Keras's documentation uses 256, but can be adjusted as necessary.\nlatent_dim = 256\n\n# Choose a batch size and a larger number of epochs:\n# batch size determines the number of sentences used at a time for training\nbatch_size = 32\n# keras' default is 100. More epochs = better model but also a longer training time\nepochs = 500","metadata":{},"cell_type":"code","id":"e036b238-87cc-4b5f-a256-98ccc0febc9a","execution_count":11,"outputs":[]},{"source":"# Encoder training setup\nencoder_inputs = Input(shape=(None, num_encoder_tokens))\nencoder_lstm = LSTM(latent_dim, return_state=True)\n# retrieve the outputs and states\nencoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\nencoder_states = [state_hidden, state_cell]\n\n# Decoder training setup:\ndecoder_inputs = Input(shape=(None, num_decoder_tokens))\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n# retrieve the LSTM outputs and states\ndecoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\n# filter outputs through the dense layer\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Build the training model:\ntraining_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\nprint(\"Model summary:\\n\")\ntraining_model.summary()\nprint(\"\\n\\n\")","metadata":{},"cell_type":"code","id":"5493b75b-ff5c-4171-9183-b089f83ba686","execution_count":12,"outputs":[{"name":"stdout","text":"Model summary:\n\nModel: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None, None, 1997)  0           []                               \n                                ]                                                                 \n                                                                                                  \n input_4 (InputLayer)           [(None, None, 3296)  0           []                               \n                                ]                                                                 \n                                                                                                  \n lstm_2 (LSTM)                  [(None, 256),        2308096     ['input_3[0][0]']                \n                                 (None, 256),                                                     \n                                 (None, 256)]                                                     \n                                                                                                  \n lstm_3 (LSTM)                  [(None, None, 256),  3638272     ['input_4[0][0]',                \n                                 (None, 256),                     'lstm_2[0][1]',                 \n                                 (None, 256)]                     'lstm_2[0][2]']                 \n                                                                                                  \n dense_1 (Dense)                (None, None, 3296)   847072      ['lstm_3[0][0]']                 \n                                                                                                  \n==================================================================================================\nTotal params: 6,793,440\nTrainable params: 6,793,440\nNon-trainable params: 0\n__________________________________________________________________________________________________\n\n\n\n","output_type":"stream"}]},{"source":"# Compile the model:\ntraining_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n\nprint(\"Training the model:\\n\")\n# Train the model:\ntraining_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n\ntraining_model.save('training_model.h5')","metadata":{"scrolled":true,"tags":[]},"cell_type":"code","id":"0a2b18fe-c67d-4fae-bfc4-7053c8161daa","execution_count":13,"outputs":[{"name":"stdout","text":"Training the model:\n\nEpoch 1/500\n188/188 [==============================] - 23s 108ms/step - loss: 1.6974 - accuracy: 0.0938 - val_loss: 1.8322 - val_accuracy: 0.1083\nEpoch 2/500\n188/188 [==============================] - 19s 104ms/step - loss: 1.5562 - accuracy: 0.1133 - val_loss: 1.7892 - val_accuracy: 0.1332\nEpoch 3/500\n188/188 [==============================] - 19s 104ms/step - loss: 1.4700 - accuracy: 0.1252 - val_loss: 1.7726 - val_accuracy: 0.1367\nEpoch 4/500\n188/188 [==============================] - 20s 104ms/step - loss: 1.4125 - accuracy: 0.1295 - val_loss: 1.7319 - val_accuracy: 0.1299\nEpoch 5/500\n188/188 [==============================] - 20s 105ms/step - loss: 1.3706 - accuracy: 0.1332 - val_loss: 1.7287 - val_accuracy: 0.1341\nEpoch 6/500\n188/188 [==============================] - 20s 104ms/step - loss: 1.3348 - accuracy: 0.1390 - val_loss: 1.7045 - val_accuracy: 0.1368\nEpoch 7/500\n188/188 [==============================] - 20s 104ms/step - loss: 1.3034 - accuracy: 0.1421 - val_loss: 1.6939 - val_accuracy: 0.1424\nEpoch 8/500\n188/188 [==============================] - 20s 104ms/step - loss: 1.2650 - accuracy: 0.1480 - val_loss: 1.6580 - val_accuracy: 0.1640\nEpoch 9/500\n188/188 [==============================] - 20s 105ms/step - loss: 1.2243 - accuracy: 0.1550 - val_loss: 1.6343 - val_accuracy: 0.1518\nEpoch 10/500\n188/188 [==============================] - 20s 104ms/step - loss: 1.1840 - accuracy: 0.1610 - val_loss: 1.6194 - val_accuracy: 0.1716\nEpoch 11/500\n188/188 [==============================] - 20s 104ms/step - loss: 1.1485 - accuracy: 0.1662 - val_loss: 1.5714 - val_accuracy: 0.1828\nEpoch 12/500\n188/188 [==============================] - 20s 104ms/step - loss: 1.1129 - accuracy: 0.1705 - val_loss: 1.5498 - val_accuracy: 0.1800\nEpoch 13/500\n188/188 [==============================] - 20s 104ms/step - loss: 1.0801 - accuracy: 0.1747 - val_loss: 1.5503 - val_accuracy: 0.1833\nEpoch 14/500\n188/188 [==============================] - 20s 105ms/step - loss: 1.0500 - accuracy: 0.1797 - val_loss: 1.5491 - val_accuracy: 0.1819\nEpoch 15/500\n188/188 [==============================] - 20s 105ms/step - loss: 1.0204 - accuracy: 0.1840 - val_loss: 1.5314 - val_accuracy: 0.1903\nEpoch 16/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.9907 - accuracy: 0.1882 - val_loss: 1.5099 - val_accuracy: 0.1992\nEpoch 17/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.9629 - accuracy: 0.1922 - val_loss: 1.5322 - val_accuracy: 0.1938\nEpoch 18/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.9385 - accuracy: 0.1956 - val_loss: 1.5093 - val_accuracy: 0.2022\nEpoch 19/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.9147 - accuracy: 0.1990 - val_loss: 1.5136 - val_accuracy: 0.1945\nEpoch 20/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.8909 - accuracy: 0.2029 - val_loss: 1.4987 - val_accuracy: 0.2036\nEpoch 21/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.8687 - accuracy: 0.2062 - val_loss: 1.5042 - val_accuracy: 0.2085\nEpoch 22/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.8471 - accuracy: 0.2088 - val_loss: 1.4867 - val_accuracy: 0.2065\nEpoch 23/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.8267 - accuracy: 0.2111 - val_loss: 1.4828 - val_accuracy: 0.2108\nEpoch 24/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.8076 - accuracy: 0.2141 - val_loss: 1.4855 - val_accuracy: 0.2116\nEpoch 25/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.7875 - accuracy: 0.2168 - val_loss: 1.4805 - val_accuracy: 0.2178\nEpoch 26/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.7699 - accuracy: 0.2191 - val_loss: 1.4798 - val_accuracy: 0.2116\nEpoch 27/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.7538 - accuracy: 0.2217 - val_loss: 1.4979 - val_accuracy: 0.2108\nEpoch 28/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.7357 - accuracy: 0.2237 - val_loss: 1.4976 - val_accuracy: 0.2059\nEpoch 29/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.7205 - accuracy: 0.2265 - val_loss: 1.4952 - val_accuracy: 0.2169\nEpoch 30/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.7052 - accuracy: 0.2286 - val_loss: 1.4984 - val_accuracy: 0.2138\nEpoch 31/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.6002 - accuracy: 0.2464 - val_loss: 1.5477 - val_accuracy: 0.2224\nEpoch 39/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.5897 - accuracy: 0.2475 - val_loss: 1.5558 - val_accuracy: 0.2241\nEpoch 40/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.5793 - accuracy: 0.2495 - val_loss: 1.5557 - val_accuracy: 0.2241\nEpoch 41/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.5685 - accuracy: 0.2507 - val_loss: 1.5601 - val_accuracy: 0.2250\nEpoch 42/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.5586 - accuracy: 0.2528 - val_loss: 1.5644 - val_accuracy: 0.2206\nEpoch 43/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.5467 - accuracy: 0.2546 - val_loss: 1.5792 - val_accuracy: 0.2228\nEpoch 44/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.5366 - accuracy: 0.2560 - val_loss: 1.5812 - val_accuracy: 0.2227\nEpoch 45/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.5286 - accuracy: 0.2570 - val_loss: 1.5922 - val_accuracy: 0.2216\nEpoch 46/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.5192 - accuracy: 0.2587 - val_loss: 1.5827 - val_accuracy: 0.2247\nEpoch 47/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.5095 - accuracy: 0.2602 - val_loss: 1.5950 - val_accuracy: 0.2244\nEpoch 48/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.5017 - accuracy: 0.2620 - val_loss: 1.5984 - val_accuracy: 0.2244\nEpoch 49/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.4955 - accuracy: 0.2626 - val_loss: 1.5897 - val_accuracy: 0.2242\nEpoch 50/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.4886 - accuracy: 0.2636 - val_loss: 1.6055 - val_accuracy: 0.2256\nEpoch 51/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.4809 - accuracy: 0.2647 - val_loss: 1.6125 - val_accuracy: 0.2230\nEpoch 52/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.4735 - accuracy: 0.2662 - val_loss: 1.6195 - val_accuracy: 0.2254\nEpoch 53/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.4670 - accuracy: 0.2672 - val_loss: 1.6382 - val_accuracy: 0.2233\nEpoch 54/500\n","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_msg_rate_limit`.\n\nCurrent values:\nServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"188/188 [==============================] - 20s 105ms/step - loss: 0.4172 - accuracy: 0.2735 - val_loss: 1.6609 - val_accuracy: 0.2254\nEpoch 60/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.4104 - accuracy: 0.2743 - val_loss: 1.6692 - val_accuracy: 0.2250\nEpoch 61/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.4029 - accuracy: 0.2756 - val_loss: 1.6898 - val_accuracy: 0.2272\nEpoch 62/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.3979 - accuracy: 0.2751 - val_loss: 1.6822 - val_accuracy: 0.2247\nEpoch 63/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.3907 - accuracy: 0.2775 - val_loss: 1.6935 - val_accuracy: 0.2267\nEpoch 64/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.3854 - accuracy: 0.2774 - val_loss: 1.7029 - val_accuracy: 0.2228\nEpoch 65/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.3790 - accuracy: 0.2789 - val_loss: 1.7014 - val_accuracy: 0.2252\nEpoch 66/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.3732 - accuracy: 0.2793 - val_loss: 1.7095 - val_accuracy: 0.2274\nEpoch 67/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.3689 - accuracy: 0.2798 - val_loss: 1.7067 - val_accuracy: 0.2254\nEpoch 68/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.3621 - accuracy: 0.2813 - val_loss: 1.7323 - val_accuracy: 0.2261\nEpoch 69/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.3586 - accuracy: 0.2809 - val_loss: 1.7362 - val_accuracy: 0.2262\nEpoch 70/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.3544 - accuracy: 0.2818 - val_loss: 1.7295 - val_accuracy: 0.2267\nEpoch 71/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.3485 - accuracy: 0.2828 - val_loss: 1.7475 - val_accuracy: 0.2272\nEpoch 72/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.3445 - accuracy: 0.2828 - val_loss: 1.7687 - val_accuracy: 0.2260\nEpoch 73/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.3394 - accuracy: 0.2834 - val_loss: 1.7849 - val_accuracy: 0.2268\nEpoch 74/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.3356 - accuracy: 0.2845 - val_loss: 1.7691 - val_accuracy: 0.2253\nEpoch 75/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.3306 - accuracy: 0.2852 - val_loss: 1.8028 - val_accuracy: 0.2270\nEpoch 76/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.3276 - accuracy: 0.2849 - val_loss: 1.7888 - val_accuracy: 0.2256\nEpoch 77/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.3232 - accuracy: 0.2860 - val_loss: 1.7908 - val_accuracy: 0.2257\nEpoch 78/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.3181 - accuracy: 0.2866 - val_loss: 1.7895 - val_accuracy: 0.2256\nEpoch 79/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.3147 - accuracy: 0.2868 - val_loss: 1.8051 - val_accuracy: 0.2243\nEpoch 80/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.3110 - accuracy: 0.2877 - val_loss: 1.8128 - val_accuracy: 0.2256\nEpoch 81/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.3058 - accuracy: 0.2879 - val_loss: 1.8062 - val_accuracy: 0.2243\nEpoch 82/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.3019 - accuracy: 0.2888 - val_loss: 1.8211 - val_accuracy: 0.2260\nEpoch 83/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2972 - accuracy: 0.2887 - val_loss: 1.8077 - val_accuracy: 0.2266\nEpoch 84/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2934 - accuracy: 0.2894 - val_loss: 1.8528 - val_accuracy: 0.2278\nEpoch 85/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2896 - accuracy: 0.2891 - val_loss: 1.8637 - val_accuracy: 0.2272\nEpoch 86/500\n188/188 [==============================] - 19s 104ms/step - loss: 0.2847 - accuracy: 0.2902 - val_loss: 1.8613 - val_accuracy: 0.2251\nEpoch 87/500\n188/188 [==============================] - 19s 102ms/step - loss: 0.2800 - accuracy: 0.2908 - val_loss: 1.8416 - val_accuracy: 0.2258\nEpoch 88/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.2774 - accuracy: 0.2906 - val_loss: 1.8553 - val_accuracy: 0.2246\nEpoch 89/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2736 - accuracy: 0.2904 - val_loss: 1.8631 - val_accuracy: 0.2254\nEpoch 90/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2700 - accuracy: 0.2907 - val_loss: 1.8726 - val_accuracy: 0.2253\nEpoch 91/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2661 - accuracy: 0.2920 - val_loss: 1.8945 - val_accuracy: 0.2244\nEpoch 92/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2626 - accuracy: 0.2914 - val_loss: 1.8714 - val_accuracy: 0.2241\nEpoch 93/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2587 - accuracy: 0.2923 - val_loss: 1.8697 - val_accuracy: 0.2261\nEpoch 94/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2571 - accuracy: 0.2920 - val_loss: 1.8813 - val_accuracy: 0.2266\nEpoch 95/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.2535 - accuracy: 0.2926 - val_loss: 1.9072 - val_accuracy: 0.2278\nEpoch 96/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2503 - accuracy: 0.2930 - val_loss: 1.9281 - val_accuracy: 0.2255\nEpoch 97/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2465 - accuracy: 0.2932 - val_loss: 1.9097 - val_accuracy: 0.2287\nEpoch 98/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2434 - accuracy: 0.2934 - val_loss: 1.9235 - val_accuracy: 0.2244\nEpoch 99/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2409 - accuracy: 0.2936 - val_loss: 1.9493 - val_accuracy: 0.2278\nEpoch 100/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2387 - accuracy: 0.2941 - val_loss: 1.9259 - val_accuracy: 0.2266\nEpoch 101/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2350 - accuracy: 0.2944 - val_loss: 1.9349 - val_accuracy: 0.2262\nEpoch 102/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2329 - accuracy: 0.2946 - val_loss: 1.9499 - val_accuracy: 0.2271\nEpoch 103/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2301 - accuracy: 0.2953 - val_loss: 1.9590 - val_accuracy: 0.2278\nEpoch 104/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2282 - accuracy: 0.2956 - val_loss: 1.9442 - val_accuracy: 0.2270\nEpoch 105/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2250 - accuracy: 0.2956 - val_loss: 1.9750 - val_accuracy: 0.2265\nEpoch 106/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2216 - accuracy: 0.2952 - val_loss: 1.9715 - val_accuracy: 0.2266\nEpoch 107/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2190 - accuracy: 0.2960 - val_loss: 1.9749 - val_accuracy: 0.2293\nEpoch 108/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2167 - accuracy: 0.2954 - val_loss: 1.9768 - val_accuracy: 0.2268\nEpoch 109/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2139 - accuracy: 0.2964 - val_loss: 1.9768 - val_accuracy: 0.2268\nEpoch 110/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2129 - accuracy: 0.2967 - val_loss: 1.9798 - val_accuracy: 0.2256\nEpoch 111/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2104 - accuracy: 0.2965 - val_loss: 2.0047 - val_accuracy: 0.2279\nEpoch 112/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2070 - accuracy: 0.2973 - val_loss: 1.9947 - val_accuracy: 0.2271\nEpoch 113/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2055 - accuracy: 0.2970 - val_loss: 2.0057 - val_accuracy: 0.2277\nEpoch 114/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2043 - accuracy: 0.2971 - val_loss: 2.0147 - val_accuracy: 0.2260\nEpoch 115/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.2013 - accuracy: 0.2977 - val_loss: 2.0487 - val_accuracy: 0.2269\nEpoch 116/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.2003 - accuracy: 0.2976 - val_loss: 2.0326 - val_accuracy: 0.2262\nEpoch 117/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.1984 - accuracy: 0.2983 - val_loss: 2.0404 - val_accuracy: 0.2248\nEpoch 118/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1967 - accuracy: 0.2980 - val_loss: 2.0567 - val_accuracy: 0.2258\nEpoch 119/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1945 - accuracy: 0.2984 - val_loss: 2.0608 - val_accuracy: 0.2250\nEpoch 120/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1882 - accuracy: 0.2987 - val_loss: 2.0348 - val_accuracy: 0.2264\nEpoch 121/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1840 - accuracy: 0.2989 - val_loss: 2.0633 - val_accuracy: 0.2252\nEpoch 122/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1812 - accuracy: 0.2990 - val_loss: 2.0909 - val_accuracy: 0.2246\nEpoch 123/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1784 - accuracy: 0.2992 - val_loss: 2.0592 - val_accuracy: 0.2267\nEpoch 124/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1774 - accuracy: 0.2988 - val_loss: 2.0809 - val_accuracy: 0.2253\nEpoch 125/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.1755 - accuracy: 0.2994 - val_loss: 2.0768 - val_accuracy: 0.2244\nEpoch 126/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1731 - accuracy: 0.2992 - val_loss: 2.1185 - val_accuracy: 0.2248\nEpoch 127/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1724 - accuracy: 0.2996 - val_loss: 2.0748 - val_accuracy: 0.2259\nEpoch 128/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1703 - accuracy: 0.3001 - val_loss: 2.0934 - val_accuracy: 0.2244\nEpoch 129/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1695 - accuracy: 0.3003 - val_loss: 2.0839 - val_accuracy: 0.2265\nEpoch 130/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1671 - accuracy: 0.3001 - val_loss: 2.1135 - val_accuracy: 0.2249\nEpoch 131/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.1665 - accuracy: 0.3002 - val_loss: 2.1182 - val_accuracy: 0.2251\nEpoch 132/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.1640 - accuracy: 0.3004 - val_loss: 2.1010 - val_accuracy: 0.2256\nEpoch 133/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1637 - accuracy: 0.3005 - val_loss: 2.1110 - val_accuracy: 0.2243\nEpoch 134/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1631 - accuracy: 0.3004 - val_loss: 2.1306 - val_accuracy: 0.2243\nEpoch 135/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1611 - accuracy: 0.3010 - val_loss: 2.1424 - val_accuracy: 0.2243\nEpoch 136/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1600 - accuracy: 0.3011 - val_loss: 2.1573 - val_accuracy: 0.2241\nEpoch 137/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1589 - accuracy: 0.3010 - val_loss: 2.1421 - val_accuracy: 0.2246\nEpoch 138/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1582 - accuracy: 0.3013 - val_loss: 2.1565 - val_accuracy: 0.2255\nEpoch 139/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1570 - accuracy: 0.3015 - val_loss: 2.1594 - val_accuracy: 0.2243\nEpoch 140/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.1566 - accuracy: 0.3018 - val_loss: 2.1655 - val_accuracy: 0.2268\nEpoch 141/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1554 - accuracy: 0.3015 - val_loss: 2.1994 - val_accuracy: 0.2226\nEpoch 142/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1543 - accuracy: 0.3021 - val_loss: 2.2041 - val_accuracy: 0.2256\nEpoch 143/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1532 - accuracy: 0.3015 - val_loss: 2.2311 - val_accuracy: 0.2245\nEpoch 144/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1522 - accuracy: 0.3018 - val_loss: 2.1937 - val_accuracy: 0.2251\nEpoch 145/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1512 - accuracy: 0.3018 - val_loss: 2.1931 - val_accuracy: 0.2238\nEpoch 146/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1502 - accuracy: 0.3020 - val_loss: 2.1986 - val_accuracy: 0.2251\nEpoch 147/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1492 - accuracy: 0.3027 - val_loss: 2.2060 - val_accuracy: 0.2248\nEpoch 148/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1485 - accuracy: 0.3021 - val_loss: 2.2385 - val_accuracy: 0.2242\nEpoch 149/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.1485 - accuracy: 0.3018 - val_loss: 2.2313 - val_accuracy: 0.2259\nEpoch 150/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1473 - accuracy: 0.3023 - val_loss: 2.2503 - val_accuracy: 0.2256\nEpoch 151/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1457 - accuracy: 0.3023 - val_loss: 2.2496 - val_accuracy: 0.2247\nEpoch 152/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1532 - accuracy: 0.3015 - val_loss: 2.2487 - val_accuracy: 0.2236\nEpoch 153/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1533 - accuracy: 0.3019 - val_loss: 2.2690 - val_accuracy: 0.2218\nEpoch 154/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1507 - accuracy: 0.3015 - val_loss: 2.2643 - val_accuracy: 0.2228\nEpoch 155/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1499 - accuracy: 0.3022 - val_loss: 2.2558 - val_accuracy: 0.2233\nEpoch 156/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1489 - accuracy: 0.3088 - val_loss: 2.2809 - val_accuracy: 0.2253\nEpoch 157/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1472 - accuracy: 0.3031 - val_loss: 2.3220 - val_accuracy: 0.2228\nEpoch 158/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1463 - accuracy: 0.3021 - val_loss: 2.3081 - val_accuracy: 0.2249\nEpoch 159/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1447 - accuracy: 0.3024 - val_loss: 2.2758 - val_accuracy: 0.2223\nEpoch 160/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1441 - accuracy: 0.3025 - val_loss: 2.2822 - val_accuracy: 0.2236\nEpoch 161/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1431 - accuracy: 0.3028 - val_loss: 2.2804 - val_accuracy: 0.2250\nEpoch 162/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1418 - accuracy: 0.3029 - val_loss: 2.2888 - val_accuracy: 0.2265\nEpoch 163/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.1418 - accuracy: 0.3074 - val_loss: 2.3177 - val_accuracy: 0.2237\nEpoch 164/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1415 - accuracy: 0.3033 - val_loss: 2.3055 - val_accuracy: 0.2251\nEpoch 165/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1405 - accuracy: 0.3030 - val_loss: 2.3143 - val_accuracy: 0.2228\nEpoch 166/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1400 - accuracy: 0.3029 - val_loss: 2.3365 - val_accuracy: 0.2241\nEpoch 167/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1397 - accuracy: 0.3104 - val_loss: 2.3530 - val_accuracy: 0.8465\nEpoch 168/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1384 - accuracy: 0.3104 - val_loss: 2.3354 - val_accuracy: 0.2254\nEpoch 169/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1369 - accuracy: 0.3038 - val_loss: 2.3349 - val_accuracy: 0.2243\nEpoch 170/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1369 - accuracy: 0.3037 - val_loss: 2.3288 - val_accuracy: 0.2225\nEpoch 171/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1364 - accuracy: 0.3039 - val_loss: 2.3483 - val_accuracy: 0.2234\nEpoch 172/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1354 - accuracy: 0.3043 - val_loss: 2.3752 - val_accuracy: 0.2211\nEpoch 173/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1359 - accuracy: 0.3038 - val_loss: 2.3635 - val_accuracy: 0.2231\nEpoch 174/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1356 - accuracy: 0.3079 - val_loss: 2.3941 - val_accuracy: 0.2238\nEpoch 175/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1342 - accuracy: 0.3039 - val_loss: 2.3750 - val_accuracy: 0.2222\nEpoch 176/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1328 - accuracy: 0.3078 - val_loss: 2.3867 - val_accuracy: 0.2218\nEpoch 177/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1326 - accuracy: 0.3042 - val_loss: 2.4280 - val_accuracy: 0.2236\nEpoch 178/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1337 - accuracy: 0.3042 - val_loss: 2.4213 - val_accuracy: 0.2235\nEpoch 179/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1317 - accuracy: 0.3075 - val_loss: 2.4141 - val_accuracy: 0.2228\nEpoch 180/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1311 - accuracy: 0.3041 - val_loss: 2.4259 - val_accuracy: 0.2236\nEpoch 181/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1305 - accuracy: 0.3050 - val_loss: 2.4084 - val_accuracy: 0.2199\nEpoch 182/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1306 - accuracy: 0.3045 - val_loss: 2.3967 - val_accuracy: 0.2223\nEpoch 183/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1294 - accuracy: 0.3042 - val_loss: 2.4644 - val_accuracy: 0.2226\nEpoch 184/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1289 - accuracy: 0.3045 - val_loss: 2.4773 - val_accuracy: 0.2227\nEpoch 185/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1289 - accuracy: 0.3048 - val_loss: 2.4335 - val_accuracy: 0.2235\nEpoch 186/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1284 - accuracy: 0.3082 - val_loss: 2.4638 - val_accuracy: 0.2242\nEpoch 187/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1268 - accuracy: 0.3046 - val_loss: 2.4700 - val_accuracy: 0.2240\nEpoch 188/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1273 - accuracy: 0.3118 - val_loss: 2.4941 - val_accuracy: 0.2235\nEpoch 189/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1265 - accuracy: 0.3046 - val_loss: 2.5074 - val_accuracy: 0.2232\nEpoch 190/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1260 - accuracy: 0.3084 - val_loss: 2.4872 - val_accuracy: 0.2196\nEpoch 191/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1254 - accuracy: 0.3052 - val_loss: 2.4918 - val_accuracy: 0.2220\nEpoch 192/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1252 - accuracy: 0.3116 - val_loss: 2.5047 - val_accuracy: 0.2234\nEpoch 193/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1257 - accuracy: 0.3053 - val_loss: 2.5206 - val_accuracy: 0.2224\nEpoch 194/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1259 - accuracy: 0.3082 - val_loss: 2.5149 - val_accuracy: 0.2250\nEpoch 195/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1235 - accuracy: 0.3053 - val_loss: 2.4996 - val_accuracy: 0.2223\nEpoch 196/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1242 - accuracy: 0.3053 - val_loss: 2.5308 - val_accuracy: 0.2235\nEpoch 197/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1233 - accuracy: 0.3057 - val_loss: 2.5107 - val_accuracy: 0.2214\nEpoch 198/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1232 - accuracy: 0.3052 - val_loss: 2.5518 - val_accuracy: 0.2238\nEpoch 199/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1235 - accuracy: 0.3127 - val_loss: 2.5431 - val_accuracy: 0.2225\nEpoch 200/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1220 - accuracy: 0.3055 - val_loss: 2.5505 - val_accuracy: 0.2226\nEpoch 201/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1223 - accuracy: 0.3052 - val_loss: 2.5761 - val_accuracy: 0.2244\nEpoch 202/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1218 - accuracy: 0.3125 - val_loss: 2.6082 - val_accuracy: 0.2221\nEpoch 203/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1218 - accuracy: 0.3052 - val_loss: 2.5607 - val_accuracy: 0.2210\nEpoch 204/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1212 - accuracy: 0.3054 - val_loss: 2.5997 - val_accuracy: 0.2222\nEpoch 205/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1217 - accuracy: 0.3055 - val_loss: 2.6094 - val_accuracy: 0.2224\nEpoch 206/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1207 - accuracy: 0.3093 - val_loss: 2.6182 - val_accuracy: 0.2204\nEpoch 207/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1195 - accuracy: 0.3056 - val_loss: 2.5840 - val_accuracy: 0.2212\nEpoch 208/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1208 - accuracy: 0.3053 - val_loss: 2.6160 - val_accuracy: 0.2216\nEpoch 209/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1204 - accuracy: 0.3055 - val_loss: 2.6156 - val_accuracy: 0.2213\nEpoch 210/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1196 - accuracy: 0.3164 - val_loss: 2.6349 - val_accuracy: 0.8420\nEpoch 211/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1195 - accuracy: 0.3091 - val_loss: 2.6724 - val_accuracy: 0.2222\nEpoch 212/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1199 - accuracy: 0.3092 - val_loss: 2.6793 - val_accuracy: 0.2220\nEpoch 213/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1180 - accuracy: 0.3057 - val_loss: 2.6805 - val_accuracy: 0.2218\nEpoch 214/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1181 - accuracy: 0.3093 - val_loss: 2.6452 - val_accuracy: 0.2205\nEpoch 215/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1177 - accuracy: 0.3056 - val_loss: 2.6765 - val_accuracy: 0.2192\nEpoch 216/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1172 - accuracy: 0.3233 - val_loss: 2.6937 - val_accuracy: 0.2192\nEpoch 217/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1174 - accuracy: 0.3060 - val_loss: 2.6549 - val_accuracy: 0.2141\nEpoch 218/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1158 - accuracy: 0.3127 - val_loss: 2.6828 - val_accuracy: 0.2191\nEpoch 219/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.1168 - accuracy: 0.3133 - val_loss: 2.7141 - val_accuracy: 0.2219\nEpoch 220/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1166 - accuracy: 0.3161 - val_loss: 2.6947 - val_accuracy: 0.2218\nEpoch 221/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1168 - accuracy: 0.3095 - val_loss: 2.7373 - val_accuracy: 0.2210\nEpoch 222/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1167 - accuracy: 0.3095 - val_loss: 2.6882 - val_accuracy: 0.2210\nEpoch 223/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1168 - accuracy: 0.3233 - val_loss: 2.6956 - val_accuracy: 0.2207\nEpoch 224/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1155 - accuracy: 0.3095 - val_loss: 2.6939 - val_accuracy: 0.2190\nEpoch 225/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1160 - accuracy: 0.3062 - val_loss: 2.7330 - val_accuracy: 0.2172\nEpoch 226/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1153 - accuracy: 0.3095 - val_loss: 2.7303 - val_accuracy: 0.2180\nEpoch 227/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1145 - accuracy: 0.3059 - val_loss: 2.7317 - val_accuracy: 0.2197\nEpoch 228/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1154 - accuracy: 0.3127 - val_loss: 2.7588 - val_accuracy: 0.2203\nEpoch 229/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1137 - accuracy: 0.3134 - val_loss: 2.7156 - val_accuracy: 0.2182\nEpoch 230/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1132 - accuracy: 0.3195 - val_loss: 2.7375 - val_accuracy: 0.2202\nEpoch 231/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1150 - accuracy: 0.3096 - val_loss: 2.7934 - val_accuracy: 0.2194\nEpoch 232/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1131 - accuracy: 0.3105 - val_loss: 2.8135 - val_accuracy: 0.2186\nEpoch 233/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1128 - accuracy: 0.3098 - val_loss: 2.7707 - val_accuracy: 0.2210\nEpoch 234/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1144 - accuracy: 0.3105 - val_loss: 2.7449 - val_accuracy: 0.2192\nEpoch 235/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1129 - accuracy: 0.3129 - val_loss: 2.7788 - val_accuracy: 0.2169\nEpoch 236/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1128 - accuracy: 0.3213 - val_loss: 2.8005 - val_accuracy: 0.2182\nEpoch 237/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1122 - accuracy: 0.3243 - val_loss: 2.8079 - val_accuracy: 0.2190\nEpoch 238/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1127 - accuracy: 0.3202 - val_loss: 2.8037 - val_accuracy: 0.2212\nEpoch 239/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1123 - accuracy: 0.3159 - val_loss: 2.8051 - val_accuracy: 0.2197\nEpoch 240/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.1113 - accuracy: 0.3067 - val_loss: 2.8121 - val_accuracy: 0.2204\nEpoch 241/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1108 - accuracy: 0.3172 - val_loss: 2.8487 - val_accuracy: 0.2192\nEpoch 242/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1123 - accuracy: 0.3064 - val_loss: 2.8245 - val_accuracy: 0.2199\nEpoch 243/500\n188/188 [==============================] - 19s 101ms/step - loss: 0.1113 - accuracy: 0.3170 - val_loss: 2.8222 - val_accuracy: 0.2183\nEpoch 244/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1118 - accuracy: 0.3102 - val_loss: 2.8053 - val_accuracy: 0.2171\nEpoch 245/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1097 - accuracy: 0.3100 - val_loss: 2.8597 - val_accuracy: 0.2175\nEpoch 246/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1109 - accuracy: 0.3105 - val_loss: 2.8792 - val_accuracy: 0.2170\nEpoch 247/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1102 - accuracy: 0.3204 - val_loss: 2.8481 - val_accuracy: 0.2196\nEpoch 248/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1092 - accuracy: 0.3074 - val_loss: 2.8180 - val_accuracy: 0.2198\nEpoch 249/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1109 - accuracy: 0.3098 - val_loss: 2.8960 - val_accuracy: 0.2160\nEpoch 250/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1096 - accuracy: 0.3134 - val_loss: 2.8387 - val_accuracy: 0.2190\nEpoch 251/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1099 - accuracy: 0.3133 - val_loss: 2.8570 - val_accuracy: 0.2185\nEpoch 252/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1099 - accuracy: 0.3100 - val_loss: 2.8484 - val_accuracy: 0.2201\nEpoch 253/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1092 - accuracy: 0.3244 - val_loss: 2.8924 - val_accuracy: 0.2188\nEpoch 254/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1089 - accuracy: 0.3172 - val_loss: 2.9125 - val_accuracy: 0.2172\nEpoch 255/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1093 - accuracy: 0.3107 - val_loss: 2.9127 - val_accuracy: 0.2156\nEpoch 256/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1083 - accuracy: 0.3166 - val_loss: 2.9354 - val_accuracy: 0.8373\nEpoch 257/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1096 - accuracy: 0.3474 - val_loss: 2.9141 - val_accuracy: 0.2189\nEpoch 258/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1089 - accuracy: 0.3104 - val_loss: 2.9326 - val_accuracy: 0.2186\nEpoch 259/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1084 - accuracy: 0.3466 - val_loss: 2.9401 - val_accuracy: 0.8373\nEpoch 260/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.1086 - accuracy: 0.3657 - val_loss: 2.9174 - val_accuracy: 0.2178\nEpoch 261/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1086 - accuracy: 0.3171 - val_loss: 2.9827 - val_accuracy: 0.2180\nEpoch 262/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1074 - accuracy: 0.3173 - val_loss: 2.9762 - val_accuracy: 0.2187\nEpoch 263/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.1088 - accuracy: 0.3068 - val_loss: 2.9391 - val_accuracy: 0.2175\nEpoch 264/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1074 - accuracy: 0.3072 - val_loss: 2.9413 - val_accuracy: 0.2187\nEpoch 265/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1073 - accuracy: 0.3134 - val_loss: 2.9719 - val_accuracy: 0.2159\nEpoch 266/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1079 - accuracy: 0.3104 - val_loss: 2.9827 - val_accuracy: 0.2177\nEpoch 267/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1064 - accuracy: 0.3247 - val_loss: 2.9757 - val_accuracy: 0.2179\nEpoch 268/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1075 - accuracy: 0.3140 - val_loss: 3.0502 - val_accuracy: 0.2148\nEpoch 269/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1067 - accuracy: 0.3144 - val_loss: 2.9956 - val_accuracy: 0.2142\nEpoch 270/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1067 - accuracy: 0.3308 - val_loss: 2.9893 - val_accuracy: 0.2163\nEpoch 271/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1055 - accuracy: 0.3105 - val_loss: 3.0291 - val_accuracy: 0.2160\nEpoch 272/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1061 - accuracy: 0.3142 - val_loss: 2.9914 - val_accuracy: 0.2171\nEpoch 273/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1058 - accuracy: 0.3201 - val_loss: 3.0357 - val_accuracy: 0.2154\nEpoch 274/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1061 - accuracy: 0.3322 - val_loss: 2.9828 - val_accuracy: 0.2126\nEpoch 275/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1058 - accuracy: 0.3139 - val_loss: 3.0233 - val_accuracy: 0.2165\nEpoch 276/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1050 - accuracy: 0.3144 - val_loss: 3.0702 - val_accuracy: 0.2142\nEpoch 277/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1049 - accuracy: 0.3249 - val_loss: 2.9975 - val_accuracy: 0.2161\nEpoch 278/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1043 - accuracy: 0.3241 - val_loss: 3.0678 - val_accuracy: 0.2149\nEpoch 279/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1047 - accuracy: 0.3553 - val_loss: 3.0171 - val_accuracy: 0.2156\nEpoch 280/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1052 - accuracy: 0.3280 - val_loss: 3.0276 - val_accuracy: 0.2153\nEpoch 281/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1043 - accuracy: 0.3115 - val_loss: 3.0649 - val_accuracy: 0.2161\nEpoch 282/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1041 - accuracy: 0.3072 - val_loss: 3.0854 - val_accuracy: 0.2135\nEpoch 283/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1039 - accuracy: 0.3176 - val_loss: 3.0841 - val_accuracy: 0.2141\nEpoch 284/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1036 - accuracy: 0.3116 - val_loss: 3.1091 - val_accuracy: 0.2148\nEpoch 285/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.1034 - accuracy: 0.3179 - val_loss: 3.1489 - val_accuracy: 0.2149\nEpoch 286/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.1049 - accuracy: 0.3142 - val_loss: 3.1476 - val_accuracy: 0.2158\nEpoch 287/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1040 - accuracy: 0.3181 - val_loss: 3.1332 - val_accuracy: 0.2433\nEpoch 288/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1034 - accuracy: 0.3150 - val_loss: 3.1357 - val_accuracy: 0.2116\nEpoch 289/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1025 - accuracy: 0.3215 - val_loss: 3.1646 - val_accuracy: 0.2154\nEpoch 290/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1029 - accuracy: 0.3125 - val_loss: 3.1715 - val_accuracy: 0.2150\nEpoch 291/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1039 - accuracy: 0.3209 - val_loss: 3.1618 - val_accuracy: 0.2144\nEpoch 292/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1030 - accuracy: 0.3139 - val_loss: 3.1783 - val_accuracy: 0.2149\nEpoch 293/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1027 - accuracy: 0.3158 - val_loss: 3.1246 - val_accuracy: 0.2154\nEpoch 294/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1023 - accuracy: 0.3110 - val_loss: 3.1779 - val_accuracy: 0.2142\nEpoch 295/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1026 - accuracy: 0.3145 - val_loss: 3.1725 - val_accuracy: 0.2121\nEpoch 296/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1020 - accuracy: 0.3215 - val_loss: 3.2418 - val_accuracy: 0.2147\nEpoch 297/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1026 - accuracy: 0.3108 - val_loss: 3.1711 - val_accuracy: 0.2137\nEpoch 298/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1020 - accuracy: 0.3252 - val_loss: 3.2292 - val_accuracy: 0.2144\nEpoch 299/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1018 - accuracy: 0.3248 - val_loss: 3.1848 - val_accuracy: 0.2118\nEpoch 300/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1022 - accuracy: 0.3148 - val_loss: 3.2563 - val_accuracy: 0.2129\nEpoch 301/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1022 - accuracy: 0.3201 - val_loss: 3.2461 - val_accuracy: 0.2154\nEpoch 302/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1023 - accuracy: 0.3477 - val_loss: 3.1997 - val_accuracy: 0.2168\nEpoch 303/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1028 - accuracy: 0.3647 - val_loss: 3.2231 - val_accuracy: 0.2124\nEpoch 304/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1010 - accuracy: 0.3209 - val_loss: 3.3016 - val_accuracy: 0.2131\nEpoch 305/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1011 - accuracy: 0.3112 - val_loss: 3.2935 - val_accuracy: 0.2117\nEpoch 306/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1007 - accuracy: 0.3151 - val_loss: 3.2472 - val_accuracy: 0.2127\nEpoch 307/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1016 - accuracy: 0.3082 - val_loss: 3.2966 - val_accuracy: 0.2117\nEpoch 308/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1012 - accuracy: 0.3181 - val_loss: 3.2721 - val_accuracy: 0.2081\nEpoch 309/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1004 - accuracy: 0.3253 - val_loss: 3.2557 - val_accuracy: 0.2108\nEpoch 310/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1005 - accuracy: 0.3360 - val_loss: 3.3307 - val_accuracy: 0.2102\nEpoch 311/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1002 - accuracy: 0.3215 - val_loss: 3.3087 - val_accuracy: 0.8288\nEpoch 312/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.1011 - accuracy: 0.3387 - val_loss: 3.3128 - val_accuracy: 0.2109\nEpoch 313/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0996 - accuracy: 0.3341 - val_loss: 3.2690 - val_accuracy: 0.2128\nEpoch 314/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0996 - accuracy: 0.3160 - val_loss: 3.2910 - val_accuracy: 0.2105\nEpoch 315/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1004 - accuracy: 0.3496 - val_loss: 3.3455 - val_accuracy: 0.2116\nEpoch 316/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1011 - accuracy: 0.3249 - val_loss: 3.2831 - val_accuracy: 0.2102\nEpoch 317/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1007 - accuracy: 0.3225 - val_loss: 3.3348 - val_accuracy: 0.2107\nEpoch 318/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1003 - accuracy: 0.3181 - val_loss: 3.3520 - val_accuracy: 0.2099\nEpoch 319/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0994 - accuracy: 0.3224 - val_loss: 3.3749 - val_accuracy: 0.2118\nEpoch 320/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1004 - accuracy: 0.3208 - val_loss: 3.3696 - val_accuracy: 0.2100\nEpoch 321/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0994 - accuracy: 0.3152 - val_loss: 3.3028 - val_accuracy: 0.2126\nEpoch 322/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0999 - accuracy: 0.3147 - val_loss: 3.3943 - val_accuracy: 0.2093\nEpoch 323/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0998 - accuracy: 0.3344 - val_loss: 3.4008 - val_accuracy: 0.2093\nEpoch 324/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0998 - accuracy: 0.3321 - val_loss: 3.3849 - val_accuracy: 0.2102\nEpoch 325/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0995 - accuracy: 0.3416 - val_loss: 3.3319 - val_accuracy: 0.2116\nEpoch 326/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0982 - accuracy: 0.3112 - val_loss: 3.3908 - val_accuracy: 0.3129\nEpoch 327/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.1000 - accuracy: 0.3118 - val_loss: 3.3879 - val_accuracy: 0.2116\nEpoch 328/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0991 - accuracy: 0.3217 - val_loss: 3.3587 - val_accuracy: 0.2097\nEpoch 329/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0985 - accuracy: 0.3158 - val_loss: 3.3797 - val_accuracy: 0.2117\nEpoch 330/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0990 - accuracy: 0.3190 - val_loss: 3.3660 - val_accuracy: 0.2105\nEpoch 331/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0999 - accuracy: 0.3151 - val_loss: 3.3260 - val_accuracy: 0.2122\nEpoch 332/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0979 - accuracy: 0.3119 - val_loss: 3.3910 - val_accuracy: 0.2109\nEpoch 333/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0980 - accuracy: 0.3087 - val_loss: 3.4137 - val_accuracy: 0.2106\nEpoch 334/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0985 - accuracy: 0.3149 - val_loss: 3.3954 - val_accuracy: 0.2104\nEpoch 335/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0980 - accuracy: 0.3154 - val_loss: 3.4084 - val_accuracy: 0.2103\nEpoch 336/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0999 - accuracy: 0.3219 - val_loss: 3.3990 - val_accuracy: 0.2132\nEpoch 337/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0988 - accuracy: 0.3255 - val_loss: 3.4512 - val_accuracy: 0.2109\nEpoch 338/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0980 - accuracy: 0.3383 - val_loss: 3.4114 - val_accuracy: 0.2098\nEpoch 339/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0972 - accuracy: 0.3151 - val_loss: 3.4515 - val_accuracy: 0.2094\nEpoch 340/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0979 - accuracy: 0.3187 - val_loss: 3.4569 - val_accuracy: 0.2105\nEpoch 341/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0979 - accuracy: 0.3221 - val_loss: 3.4917 - val_accuracy: 0.2071\nEpoch 342/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0976 - accuracy: 0.3158 - val_loss: 3.4531 - val_accuracy: 0.2104\nEpoch 343/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0964 - accuracy: 0.3121 - val_loss: 3.4994 - val_accuracy: 0.2076\nEpoch 344/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0972 - accuracy: 0.3086 - val_loss: 3.4964 - val_accuracy: 0.2100\nEpoch 345/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0984 - accuracy: 0.3221 - val_loss: 3.5167 - val_accuracy: 0.2063\nEpoch 346/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0968 - accuracy: 0.3182 - val_loss: 3.4674 - val_accuracy: 0.2096\nEpoch 347/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0972 - accuracy: 0.3282 - val_loss: 3.4900 - val_accuracy: 0.2088\nEpoch 348/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0983 - accuracy: 0.3289 - val_loss: 3.5384 - val_accuracy: 0.2071\nEpoch 349/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0966 - accuracy: 0.3149 - val_loss: 3.4810 - val_accuracy: 0.2083\nEpoch 350/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0971 - accuracy: 0.3184 - val_loss: 3.5673 - val_accuracy: 0.2061\nEpoch 351/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.0967 - accuracy: 0.3222 - val_loss: 3.4713 - val_accuracy: 0.2069\nEpoch 352/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0960 - accuracy: 0.3085 - val_loss: 3.5169 - val_accuracy: 0.2079\nEpoch 353/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0958 - accuracy: 0.3122 - val_loss: 3.5573 - val_accuracy: 0.2072\nEpoch 354/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0961 - accuracy: 0.3152 - val_loss: 3.5370 - val_accuracy: 0.2073\nEpoch 355/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0961 - accuracy: 0.3086 - val_loss: 3.5508 - val_accuracy: 0.2070\nEpoch 356/500\n188/188 [==============================] - 20s 104ms/step - loss: 0.0958 - accuracy: 0.3223 - val_loss: 3.5756 - val_accuracy: 0.2076\nEpoch 357/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0960 - accuracy: 0.3125 - val_loss: 3.5717 - val_accuracy: 0.2088\nEpoch 358/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0963 - accuracy: 0.3182 - val_loss: 3.5451 - val_accuracy: 0.2083\nEpoch 359/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0964 - accuracy: 0.3298 - val_loss: 3.5497 - val_accuracy: 0.2094\nEpoch 360/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0954 - accuracy: 0.3258 - val_loss: 3.5638 - val_accuracy: 0.2070\nEpoch 361/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0967 - accuracy: 0.3257 - val_loss: 3.5893 - val_accuracy: 0.2051\nEpoch 362/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0969 - accuracy: 0.3159 - val_loss: 3.5870 - val_accuracy: 0.2063\nEpoch 363/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0947 - accuracy: 0.3287 - val_loss: 3.5742 - val_accuracy: 0.2075\nEpoch 364/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0967 - accuracy: 0.3168 - val_loss: 3.6767 - val_accuracy: 0.2040\nEpoch 365/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0958 - accuracy: 0.3116 - val_loss: 3.6504 - val_accuracy: 0.2059\nEpoch 366/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0952 - accuracy: 0.3223 - val_loss: 3.6405 - val_accuracy: 0.2034\nEpoch 367/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0949 - accuracy: 0.3124 - val_loss: 3.6825 - val_accuracy: 0.2062\nEpoch 368/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0964 - accuracy: 0.3184 - val_loss: 3.5882 - val_accuracy: 0.2069\nEpoch 369/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0950 - accuracy: 0.3159 - val_loss: 3.6800 - val_accuracy: 0.2054\nEpoch 370/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0960 - accuracy: 0.3215 - val_loss: 3.6665 - val_accuracy: 0.2061\nEpoch 371/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0950 - accuracy: 0.3117 - val_loss: 3.6946 - val_accuracy: 0.2048\nEpoch 372/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0942 - accuracy: 0.3221 - val_loss: 3.6666 - val_accuracy: 0.2066\nEpoch 373/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0955 - accuracy: 0.3158 - val_loss: 3.7120 - val_accuracy: 0.2066\nEpoch 374/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0952 - accuracy: 0.3159 - val_loss: 3.7158 - val_accuracy: 0.2041\nEpoch 375/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0957 - accuracy: 0.3117 - val_loss: 3.7196 - val_accuracy: 0.2063\nEpoch 376/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.0950 - accuracy: 0.3216 - val_loss: 3.6731 - val_accuracy: 0.2058\nEpoch 377/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0937 - accuracy: 0.3322 - val_loss: 3.6221 - val_accuracy: 0.2047\nEpoch 378/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0954 - accuracy: 0.3660 - val_loss: 3.7585 - val_accuracy: 0.2058\nEpoch 379/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0941 - accuracy: 0.3351 - val_loss: 3.6601 - val_accuracy: 0.2039\nEpoch 380/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0944 - accuracy: 0.3157 - val_loss: 3.7180 - val_accuracy: 0.2039\nEpoch 381/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0941 - accuracy: 0.3218 - val_loss: 3.6852 - val_accuracy: 0.2061\nEpoch 382/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0942 - accuracy: 0.3087 - val_loss: 3.6970 - val_accuracy: 0.2087\nEpoch 383/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0933 - accuracy: 0.3151 - val_loss: 3.7172 - val_accuracy: 0.2074\nEpoch 384/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0952 - accuracy: 0.3257 - val_loss: 3.7243 - val_accuracy: 0.2035\nEpoch 385/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0942 - accuracy: 0.3337 - val_loss: 3.7533 - val_accuracy: 0.2050\nEpoch 386/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0938 - accuracy: 0.3125 - val_loss: 3.7420 - val_accuracy: 0.2049\nEpoch 387/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0953 - accuracy: 0.3188 - val_loss: 3.7557 - val_accuracy: 0.2060\nEpoch 388/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0934 - accuracy: 0.3195 - val_loss: 3.8299 - val_accuracy: 0.8193\nEpoch 389/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0945 - accuracy: 0.3188 - val_loss: 3.7606 - val_accuracy: 0.2059\nEpoch 390/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0941 - accuracy: 0.3191 - val_loss: 3.7397 - val_accuracy: 0.2039\nEpoch 391/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0940 - accuracy: 0.3157 - val_loss: 3.7377 - val_accuracy: 0.2050\nEpoch 392/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0926 - accuracy: 0.3157 - val_loss: 3.8257 - val_accuracy: 0.8138\nEpoch 393/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0946 - accuracy: 0.3330 - val_loss: 3.7746 - val_accuracy: 0.2042\nEpoch 394/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0936 - accuracy: 0.3158 - val_loss: 3.7892 - val_accuracy: 0.2025\nEpoch 395/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0935 - accuracy: 0.3324 - val_loss: 3.7984 - val_accuracy: 0.2053\nEpoch 396/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0934 - accuracy: 0.3259 - val_loss: 3.7653 - val_accuracy: 0.2068\nEpoch 397/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0942 - accuracy: 0.3291 - val_loss: 3.8392 - val_accuracy: 0.2061\nEpoch 398/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0920 - accuracy: 0.3314 - val_loss: 3.7454 - val_accuracy: 0.2044\nEpoch 399/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0932 - accuracy: 0.3262 - val_loss: 3.7961 - val_accuracy: 0.2045\nEpoch 400/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0932 - accuracy: 0.3220 - val_loss: 3.9029 - val_accuracy: 0.2036\nEpoch 401/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0934 - accuracy: 0.3230 - val_loss: 3.8445 - val_accuracy: 0.8234\nEpoch 402/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0936 - accuracy: 0.3256 - val_loss: 3.8259 - val_accuracy: 0.2050\nEpoch 403/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0933 - accuracy: 0.3320 - val_loss: 3.8298 - val_accuracy: 0.2032\nEpoch 404/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0921 - accuracy: 0.3292 - val_loss: 3.8811 - val_accuracy: 0.2024\nEpoch 405/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0922 - accuracy: 0.3191 - val_loss: 3.9235 - val_accuracy: 0.2004\nEpoch 406/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0928 - accuracy: 0.3290 - val_loss: 3.8519 - val_accuracy: 0.2033\nEpoch 407/500\n188/188 [==============================] - 20s 107ms/step - loss: 0.0937 - accuracy: 0.3156 - val_loss: 3.8346 - val_accuracy: 0.2038\nEpoch 408/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0926 - accuracy: 0.3123 - val_loss: 3.9085 - val_accuracy: 0.2062\nEpoch 409/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0927 - accuracy: 0.3250 - val_loss: 3.9444 - val_accuracy: 0.2041\nEpoch 410/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0931 - accuracy: 0.3156 - val_loss: 3.9217 - val_accuracy: 0.2025\nEpoch 411/500\n188/188 [==============================] - 19s 103ms/step - loss: 0.0920 - accuracy: 0.3086 - val_loss: 3.9291 - val_accuracy: 0.2039\nEpoch 412/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0933 - accuracy: 0.3123 - val_loss: 3.9264 - val_accuracy: 0.2020\nEpoch 413/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0931 - accuracy: 0.3122 - val_loss: 3.8967 - val_accuracy: 0.2018\nEpoch 414/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0920 - accuracy: 0.3319 - val_loss: 3.8963 - val_accuracy: 0.8203\nEpoch 415/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0923 - accuracy: 0.3356 - val_loss: 3.9775 - val_accuracy: 0.2027\nEpoch 416/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0926 - accuracy: 0.3425 - val_loss: 3.9716 - val_accuracy: 0.8179\nEpoch 417/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0929 - accuracy: 0.3404 - val_loss: 4.0040 - val_accuracy: 0.2024\nEpoch 418/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0927 - accuracy: 0.3158 - val_loss: 4.0244 - val_accuracy: 0.2022\nEpoch 419/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0927 - accuracy: 0.3083 - val_loss: 4.0144 - val_accuracy: 0.1980\nEpoch 420/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0928 - accuracy: 0.3162 - val_loss: 3.9746 - val_accuracy: 0.1997\nEpoch 421/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0926 - accuracy: 0.3155 - val_loss: 3.9791 - val_accuracy: 0.1999\nEpoch 422/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0917 - accuracy: 0.3089 - val_loss: 3.9955 - val_accuracy: 0.2008\nEpoch 423/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0918 - accuracy: 0.3090 - val_loss: 3.9714 - val_accuracy: 0.2029\nEpoch 424/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0918 - accuracy: 0.3160 - val_loss: 4.0527 - val_accuracy: 0.2020\nEpoch 425/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0923 - accuracy: 0.3312 - val_loss: 4.0383 - val_accuracy: 0.8177\nEpoch 426/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0927 - accuracy: 0.3160 - val_loss: 4.0188 - val_accuracy: 0.1989\nEpoch 427/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0920 - accuracy: 0.3131 - val_loss: 3.9707 - val_accuracy: 0.2005\nEpoch 428/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0924 - accuracy: 0.3394 - val_loss: 4.0359 - val_accuracy: 0.1968\nEpoch 429/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0915 - accuracy: 0.3360 - val_loss: 3.9609 - val_accuracy: 0.2018\nEpoch 430/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0921 - accuracy: 0.3354 - val_loss: 4.0348 - val_accuracy: 0.1991\nEpoch 431/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0904 - accuracy: 0.3196 - val_loss: 3.9866 - val_accuracy: 0.2009\nEpoch 432/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0926 - accuracy: 0.3357 - val_loss: 4.0021 - val_accuracy: 0.8157\nEpoch 433/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0913 - accuracy: 0.3373 - val_loss: 3.9846 - val_accuracy: 0.1999\nEpoch 434/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0917 - accuracy: 0.3451 - val_loss: 4.0844 - val_accuracy: 0.1997\nEpoch 435/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0919 - accuracy: 0.3128 - val_loss: 4.1271 - val_accuracy: 0.1984\nEpoch 436/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0919 - accuracy: 0.3123 - val_loss: 4.1128 - val_accuracy: 0.7859\nEpoch 437/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0917 - accuracy: 0.3267 - val_loss: 3.9918 - val_accuracy: 0.2008\nEpoch 438/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0921 - accuracy: 0.3394 - val_loss: 4.0820 - val_accuracy: 0.1999\nEpoch 439/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0925 - accuracy: 0.3260 - val_loss: 4.0577 - val_accuracy: 0.2000\nEpoch 440/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0919 - accuracy: 0.3122 - val_loss: 4.1006 - val_accuracy: 0.2004\nEpoch 441/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0909 - accuracy: 0.3395 - val_loss: 4.0817 - val_accuracy: 0.1958\nEpoch 442/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0913 - accuracy: 0.3369 - val_loss: 4.0820 - val_accuracy: 0.2002\nEpoch 443/500\n188/188 [==============================] - 20s 107ms/step - loss: 0.0900 - accuracy: 0.3183 - val_loss: 4.0663 - val_accuracy: 0.1999\nEpoch 444/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0906 - accuracy: 0.3101 - val_loss: 4.2110 - val_accuracy: 0.1977\nEpoch 445/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0914 - accuracy: 0.3228 - val_loss: 4.0531 - val_accuracy: 0.1985\nEpoch 446/500\n188/188 [==============================] - 20s 107ms/step - loss: 0.0902 - accuracy: 0.3344 - val_loss: 4.1538 - val_accuracy: 0.1993\nEpoch 447/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0919 - accuracy: 0.3245 - val_loss: 4.1780 - val_accuracy: 0.1974\nEpoch 448/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0906 - accuracy: 0.3094 - val_loss: 4.0972 - val_accuracy: 0.1979\nEpoch 449/500\n188/188 [==============================] - 19s 104ms/step - loss: 0.0903 - accuracy: 0.3218 - val_loss: 4.1936 - val_accuracy: 0.1980\nEpoch 450/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0901 - accuracy: 0.3267 - val_loss: 4.2143 - val_accuracy: 0.1963\nEpoch 451/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0910 - accuracy: 0.3193 - val_loss: 4.1477 - val_accuracy: 0.1987\nEpoch 452/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0909 - accuracy: 0.3263 - val_loss: 4.1287 - val_accuracy: 0.2003\nEpoch 453/500\n188/188 [==============================] - 20s 107ms/step - loss: 0.0911 - accuracy: 0.3253 - val_loss: 4.1233 - val_accuracy: 0.1982\nEpoch 454/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0899 - accuracy: 0.3260 - val_loss: 4.1009 - val_accuracy: 0.8183\nEpoch 455/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0893 - accuracy: 0.3208 - val_loss: 4.1948 - val_accuracy: 0.1993\nEpoch 456/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0901 - accuracy: 0.3122 - val_loss: 4.1436 - val_accuracy: 0.1983\nEpoch 457/500\n188/188 [==============================] - 20s 107ms/step - loss: 0.0901 - accuracy: 0.3493 - val_loss: 4.2113 - val_accuracy: 0.1974\nEpoch 458/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0893 - accuracy: 0.3225 - val_loss: 4.1447 - val_accuracy: 0.1986\nEpoch 459/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0896 - accuracy: 0.3534 - val_loss: 4.2673 - val_accuracy: 0.8139\nEpoch 460/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0900 - accuracy: 0.3399 - val_loss: 4.1972 - val_accuracy: 0.8152\nEpoch 461/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0898 - accuracy: 0.4146 - val_loss: 4.1353 - val_accuracy: 0.1956\nEpoch 462/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0903 - accuracy: 0.3192 - val_loss: 4.1743 - val_accuracy: 0.1979\nEpoch 463/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0900 - accuracy: 0.3196 - val_loss: 4.2183 - val_accuracy: 0.1961\nEpoch 464/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0892 - accuracy: 0.3335 - val_loss: 4.1933 - val_accuracy: 0.1954\nEpoch 465/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0893 - accuracy: 0.3468 - val_loss: 4.1894 - val_accuracy: 0.1980\nEpoch 466/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0907 - accuracy: 0.3302 - val_loss: 4.2242 - val_accuracy: 0.1976\nEpoch 467/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0908 - accuracy: 0.3263 - val_loss: 4.2318 - val_accuracy: 0.1969\nEpoch 468/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0897 - accuracy: 0.3267 - val_loss: 4.2666 - val_accuracy: 0.1965\nEpoch 469/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0897 - accuracy: 0.3367 - val_loss: 4.2479 - val_accuracy: 0.1986\nEpoch 470/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0897 - accuracy: 0.3126 - val_loss: 4.2128 - val_accuracy: 0.1982\nEpoch 471/500\n188/188 [==============================] - 20s 107ms/step - loss: 0.0894 - accuracy: 0.3744 - val_loss: 4.2806 - val_accuracy: 0.1984\nEpoch 472/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0894 - accuracy: 0.3344 - val_loss: 4.1915 - val_accuracy: 0.1983\nEpoch 473/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0896 - accuracy: 0.3396 - val_loss: 4.2883 - val_accuracy: 0.8076\nEpoch 474/500\n188/188 [==============================] - 20s 107ms/step - loss: 0.0897 - accuracy: 0.3198 - val_loss: 4.2811 - val_accuracy: 0.1960\nEpoch 475/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0888 - accuracy: 0.3242 - val_loss: 4.3723 - val_accuracy: 0.1960\nEpoch 476/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0896 - accuracy: 0.3126 - val_loss: 4.3204 - val_accuracy: 0.1967\nEpoch 477/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0899 - accuracy: 0.3332 - val_loss: 4.3309 - val_accuracy: 0.1986\nEpoch 478/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0906 - accuracy: 0.3267 - val_loss: 4.3280 - val_accuracy: 0.1974\nEpoch 479/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0895 - accuracy: 0.3265 - val_loss: 4.3566 - val_accuracy: 0.1962\nEpoch 480/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0893 - accuracy: 0.3262 - val_loss: 4.4192 - val_accuracy: 0.1941\nEpoch 481/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0895 - accuracy: 0.3167 - val_loss: 4.3841 - val_accuracy: 0.1942\nEpoch 482/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0906 - accuracy: 0.3185 - val_loss: 4.3473 - val_accuracy: 0.1990\nEpoch 483/500\n188/188 [==============================] - 20s 107ms/step - loss: 0.0891 - accuracy: 0.3135 - val_loss: 4.3719 - val_accuracy: 0.1969\nEpoch 484/500\n188/188 [==============================] - 19s 104ms/step - loss: 0.0894 - accuracy: 0.3290 - val_loss: 4.4649 - val_accuracy: 0.1960\nEpoch 485/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0883 - accuracy: 0.3310 - val_loss: 4.3540 - val_accuracy: 0.1937\nEpoch 486/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0901 - accuracy: 0.3256 - val_loss: 4.2870 - val_accuracy: 0.1968\nEpoch 487/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0886 - accuracy: 0.3306 - val_loss: 4.3944 - val_accuracy: 0.1948\nEpoch 488/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0894 - accuracy: 0.3365 - val_loss: 4.4002 - val_accuracy: 0.1960\nEpoch 489/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0894 - accuracy: 0.3226 - val_loss: 4.4182 - val_accuracy: 0.1964\nEpoch 490/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0901 - accuracy: 0.3234 - val_loss: 4.4531 - val_accuracy: 0.1938\nEpoch 491/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0890 - accuracy: 0.3612 - val_loss: 4.4260 - val_accuracy: 0.1961\nEpoch 492/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0899 - accuracy: 0.3539 - val_loss: 4.3613 - val_accuracy: 0.1964\nEpoch 493/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0888 - accuracy: 0.3267 - val_loss: 4.4126 - val_accuracy: 0.1968\nEpoch 494/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0885 - accuracy: 0.3200 - val_loss: 4.4074 - val_accuracy: 0.1962\nEpoch 495/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0899 - accuracy: 0.3408 - val_loss: 4.4216 - val_accuracy: 0.1946\nEpoch 496/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0890 - accuracy: 0.3202 - val_loss: 4.4643 - val_accuracy: 0.1948\nEpoch 497/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0904 - accuracy: 0.3225 - val_loss: 4.4535 - val_accuracy: 0.1971\nEpoch 498/500\n188/188 [==============================] - 20s 106ms/step - loss: 0.0889 - accuracy: 0.3194 - val_loss: 4.4107 - val_accuracy: 0.1962\nEpoch 499/500\n188/188 [==============================] - 19s 104ms/step - loss: 0.0901 - accuracy: 0.3130 - val_loss: 4.5176 - val_accuracy: 0.1936\nEpoch 500/500\n188/188 [==============================] - 20s 105ms/step - loss: 0.0878 - accuracy: 0.3165 - val_loss: 4.5080 - val_accuracy: 0.1952\n","output_type":"stream"}]},{"source":"# plot the model accuracy and loss\nperf_vals = pd.DataFrame()\nperf_vals['loss'] = training_model.history.history['loss']\nperf_vals['val_loss'] = training_model.history.history['val_loss']\nperf_vals['accuracy'] = training_model.history.history['accuracy']\nperf_vals['val_accuracy'] = training_model.history.history['val_accuracy']\nperf_vals['epoch'] = range(1, len(perf_vals) + 1)\n\nfig, axs = plt.subplots(1, 2)\n\nsns.lineplot(x=\"epoch\", y=\"loss\", data=perf_vals, ax=axs[0])\nsns.lineplot(x=\"epoch\", y=\"val_loss\", data=perf_vals, ax=axs[0])\n\nsns.lineplot(x=\"epoch\", y=\"accuracy\", data=perf_vals, ax=axs[1])\nsns.lineplot(x=\"epoch\", y=\"val_accuracy\", data=perf_vals, ax=axs[1])\n\nplt.tight_layout()\nsns.despine()","metadata":{},"cell_type":"code","id":"8290f992-94de-42e4-9103-0c12601b47e5","execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"source":"**Model Testing**\n\n**CAUTION:** This code can take a while to run... anywhere from 20 minutes to several hours. When it is finished, the translations will appear.","metadata":{},"cell_type":"markdown","id":"7d414bbd-29d8-400c-b640-553da4c76015"},{"source":"# from preprocessing import input_features_dict, target_features_dict, reverse_input_features_dict, reverse_target_features_dict, max_decoder_seq_length, input_docs, target_docs, \\\n# input_tokens, target_tokens\n# from training_model import encoder_inputs, decoder_inputs, encoder_states, decoder_lstm, decoder_dense, encoder_input_data, num_decoder_tokens, latent_dim\n\nfrom tensorflow import keras\nfrom keras.layers import Input, LSTM, Dense\nfrom keras.models import Model, load_model\nimport numpy as np","metadata":{"scrolled":true,"tags":[]},"cell_type":"code","id":"08c921d0-efe6-4d80-a995-b9d4d49eacae","execution_count":15,"outputs":[]},{"source":"# these lines of code are only necessary because we're using a saved model\ntraining_model = load_model('training_model.h5')\nencoder_inputs = training_model.input[0]\nencoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\nencoder_states = [state_h_enc, state_c_enc]\n\n# Build the encoder test model:\nencoder_model = Model(encoder_inputs, encoder_states)\n\n# this is the same value as above\nlatent_dim = 256\n# Build the two decoder state input layers\ndecoder_state_input_hidden = Input(shape=(latent_dim,))\ndecoder_state_input_cell = Input(shape=(latent_dim,))\n# Put them into a list\ndecoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n# Call the decoder LSTM\ndecoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\ndecoder_states = [state_hidden, state_cell]\n# Redefine the decoder outputs\ndecoder_outputs = decoder_dense(decoder_outputs)\n# Build the decoder test model\ndecoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n\ndef decode_sequence(test_input):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(test_input)\n\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\n    # Populate the first token of target sequence with the start token.\n    target_seq[0, 0, target_features_dict['<START>']] = 1.\n\n    # Sampling loop for a batch of sequences (to simplify, here we assume a batch of size 1).\n    decoded_sentence = ''\n\n    stop_condition = False\n    while not stop_condition:\n        # Run the decoder model to get possible output tokens (with probabilities) & states\n        output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n\n        # Choose token with highest probability\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = reverse_target_features_dict[sampled_token_index]\n        decoded_sentence += \" \" + sampled_token\n\n        # Exit condition: either hit max length or find stop token.\n        if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1, 1, num_decoder_tokens))\n        target_seq[0, 0, sampled_token_index] = 1.\n\n        # Update states\n        states_value = [hidden_state, cell_state]\n\n    return decoded_sentence\n\n\n# CHANGE RANGE (NUMBER OF TEST SENTENCES TO TRANSLATE) AS YOU PLEASE\nfor seq_index in range(100):\n    test_input = encoder_input_data[seq_index: seq_index + 1]\n    decoded_sentence = decode_sequence(test_input)\n    print('-')\n    print('Input sentence:', input_docs[seq_index])\n    print('Decoded sentence:', decoded_sentence)","metadata":{},"cell_type":"code","id":"20ad57d2-f68a-4613-b6ea-ab7e4f22dbb4","execution_count":16,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 346ms/step\n1/1 [==============================] - 0s 318ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n-\nInput sentence: Go.\nDecoded sentence:  Geh . <END>\n1/1 [==============================] - 0s 32ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n-\nInput sentence: Hi.\nDecoded sentence:  Grüß Gott ! <END>\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Hi.\nDecoded sentence:  Grüß Gott ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Run!\nDecoded sentence:  Lauf ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n-\nInput sentence: Run.\nDecoded sentence:  Lauf ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Wow!\nDecoded sentence:  Potzdonner ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 50ms/step\n-\nInput sentence: Wow!\nDecoded sentence:  Potzdonner ! <END>\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 42ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 32ms/step\n-\nInput sentence: Duck!\nDecoded sentence:  Kopf runter ! <END>\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n-\nInput sentence: Fire!\nDecoded sentence:  Feuer ! <END>\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Help!\nDecoded sentence:  Zu Hülf ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Help!\nDecoded sentence:  Zu Hülf ! <END>\n1/1 [==============================] - 0s 37ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n-\nInput sentence: Stay.\nDecoded sentence:  Bleib ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n-\nInput sentence: Stop!\nDecoded sentence:  Stopp ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Stop!\nDecoded sentence:  Stopp ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n-\nInput sentence: Wait!\nDecoded sentence:  Warte ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Wait.\nDecoded sentence:  Warte . <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Begin.\nDecoded sentence:  Fang an . <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Do it.\nDecoded sentence:  Mache es ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 57ms/step\n1/1 [==============================] - 0s 17ms/step\n-\nInput sentence: Do it.\nDecoded sentence:  Mache es ! <END>\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n-\nInput sentence: Go on.\nDecoded sentence:  Mach weiter . <END>\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n-\nInput sentence: Hello!\nDecoded sentence:  Hallo ! <END>\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 41ms/step\n1/1 [==============================] - 0s 18ms/step\n-\nInput sentence: Hello!\nDecoded sentence:  Hallo ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Hello.\nDecoded sentence:  Hallo ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 45ms/step\n-\nInput sentence: Hurry!\nDecoded sentence:  Schnell ! <END>\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n-\nInput sentence: Hurry!\nDecoded sentence:  Schnell ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: I hid.\nDecoded sentence:  Ich versteckte mich\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: I hid.\nDecoded sentence:  Ich versteckte mich\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: I ran.\nDecoded sentence:  Ich rannte . <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: I see.\nDecoded sentence:  Ich verstehe . <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: I see.\nDecoded sentence:  Ich verstehe . <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: I try.\nDecoded sentence:  Ich probiere es\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: I try.\nDecoded sentence:  Ich probiere es\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: I won!\nDecoded sentence:  Ich hab gewonnen\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: I won!\nDecoded sentence:  Ich hab gewonnen\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 37ms/step\n-\nInput sentence: I won.\nDecoded sentence:  Ich habe gewonnen\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 52ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Oh no!\nDecoded sentence:  Oh , Nein ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 39ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Relax.\nDecoded sentence:  Entspann dich .\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Shoot!\nDecoded sentence:  Feuer ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 37ms/step\n-\nInput sentence: Shoot!\nDecoded sentence:  Feuer ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 59ms/step\n1/1 [==============================] - 0s 17ms/step\n-\nInput sentence: Smile.\nDecoded sentence:  Lächeln ! <END>\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Sorry?\nDecoded sentence:  Entschuldigung ?\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Ask me.\nDecoded sentence:  Fragt mich ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: Ask me.\nDecoded sentence:  Fragt mich ! <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Ask me.\nDecoded sentence:  Fragt mich ! <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: Attack!\nDecoded sentence:  Attacke ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n-\nInput sentence: Attack!\nDecoded sentence:  Attacke ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 31ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: Buy it.\nDecoded sentence:  Kauf ’ s ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 58ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: Cheers!\nDecoded sentence:  Irre dann ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Eat it.\nDecoded sentence:  Iss es . <END>\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Eat up.\nDecoded sentence:  Iss auf ! <END>\n1/1 [==============================] - 0s 41ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Eat up.\nDecoded sentence:  Iss auf ! <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: Eat up.\nDecoded sentence:  Iss auf ! <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Freeze!\nDecoded sentence:  Stehenbleiben !\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 32ms/step\n-\nInput sentence: Freeze!\nDecoded sentence:  Stehenbleiben !\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: Go now.\nDecoded sentence:  Geh jetzt ! <END>\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: Got it!\nDecoded sentence:  Ich hab ! <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Got it!\nDecoded sentence:  Ich hab ! <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: Got it!\nDecoded sentence:  Ich hab ! <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: Got it?\nDecoded sentence:  Kapiert ? <END>\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 37ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: Got it?\nDecoded sentence:  Kapiert ? <END>\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 57ms/step\n-\nInput sentence: Got it?\nDecoded sentence:  Kapiert ? <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: He ran.\nDecoded sentence:  Er rannte . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: He ran.\nDecoded sentence:  Er rannte . <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 44ms/step\n-\nInput sentence: Hop in.\nDecoded sentence:  Mach mit ! <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n-\nInput sentence: Hop in.\nDecoded sentence:  Mach mit ! <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: Hug me.\nDecoded sentence:  Umarme mich ! <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: Hug me.\nDecoded sentence:  Umarme mich ! <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: Hug me.\nDecoded sentence:  Umarme mich ! <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I care.\nDecoded sentence:  Mir ist es wichtig\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I fell.\nDecoded sentence:  Ich stürzte . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 37ms/step\n-\nInput sentence: I fell.\nDecoded sentence:  Ich stürzte . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: I fell.\nDecoded sentence:  Ich stürzte . <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I fell.\nDecoded sentence:  Ich stürzte . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 48ms/step\n-\nInput sentence: I fell.\nDecoded sentence:  Ich stürzte . <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 34ms/step\n-\nInput sentence: I fled.\nDecoded sentence:  Ich flüchtete .\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I fled.\nDecoded sentence:  Ich flüchtete .\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 33ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: I know.\nDecoded sentence:  Ich weiß . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I lied.\nDecoded sentence:  Ich habe gelogen\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I lost.\nDecoded sentence:  Ich habe verloren\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I paid.\nDecoded sentence:  Ich zahlte . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I paid.\nDecoded sentence:  Ich zahlte . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I pass.\nDecoded sentence:  Ich passe . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: I sang.\nDecoded sentence:  Ich sang . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I spit.\nDecoded sentence:  Ich habe gespuckt\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I spit.\nDecoded sentence:  Ich habe gespuckt\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: I swim.\nDecoded sentence:  Ich schwimme . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I wept.\nDecoded sentence:  Ich weinte . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 41ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 39ms/step\n-\nInput sentence: I wept.\nDecoded sentence:  Ich weinte . <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 25ms/step\n-\nInput sentence: I'm 19.\nDecoded sentence:  Ich bin 19 . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I'm 19.\nDecoded sentence:  Ich bin 19 . <END>\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: I'm OK.\nDecoded sentence:  Mir geht's gut .\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 47ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: I'm OK.\nDecoded sentence:  Mir geht's gut .\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I'm up.\nDecoded sentence:  Ich bin wach . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: I'm up.\nDecoded sentence:  Ich bin wach . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: Listen.\nDecoded sentence:  Hört zu . <END>\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n-\nInput sentence: No way!\nDecoded sentence:  Ausgeschlossen !\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: No way!\nDecoded sentence:  Ausgeschlossen !\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: No way!\nDecoded sentence:  Ausgeschlossen !\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n-\nInput sentence: No way!\nDecoded sentence:  Ausgeschlossen !\n1/1 [==============================] - 0s 13ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 36ms/step\n-\nInput sentence: No way!\nDecoded sentence:  Ausgeschlossen !\n","output_type":"stream"}]},{"source":"","metadata":{},"cell_type":"code","id":"3b02cf1f-f060-4885-a965-89c62fd10bb2","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}